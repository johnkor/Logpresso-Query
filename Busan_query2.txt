>>  파서 생성 fgate

>> Protocol lookup 생성
protocol   key
1	ICMP
17	UDP
6	TCP

>>  fortigate 박화벽 로그 적재

set filepath = concat("D:\\logsample\\fortigate\\fortigate", ".log") 
| textfile $("filepath") 
| limit 100 
|  parse fgate 
| summary
--------ok?-----------------

set filepath = concat("D:\\logsample\\fortigate\\fortigate", ".log") 
| textfile $("filepath")  |  limit 10000
| import FW_fortigate3

---------방화벽로그-----정규화-------------
 table limit=10000 FW_fortigate
  | eval dst_port = long(dst_port), 
	duration = long(duration), 
	dst_ip = ip(dst_ip), 
	recv_bytes = long(recv_bytes),
	recv_pkts = long(recv_pkts),
	sent_bytes = long(sent_bytes),
	sent_pkts = long(sent_pkts),
	src_ip = ip(src_ip),
	src_port = long(src_port),
	tran_ip = ip(tran_ip),
	tran_port = long(tran_port),
	tran_sip = ip(tran_sip),
	tran_sport = long(tran_sport)
  | lookup Protocol2 protocol output key as protocol 	
  | eval _time = date(concat(date, " ", time), "yyyy-MM-dd HH:mm:ss")
  | eval time = string(_time, "yyyy-MM-dd HH:mm:ss")
  | import session_FW_fortigate

>> --------------포트번호 적재-------------

csvfile d:\logsample\port-numbers.csv 
| eval Protocol = upper(Protocol) 
| eval PortNumberL = long(PortNumber)
| fields PortNumber, Protocol, Description, ServiceName, UnauthorizedUseReported, RegistrationDate, ServiceCode, Reference 
| import Port



2-2 table 쿼리 명령어

table limit=1000000 FW_fortigate        <SHIFT> + <ENTER>

table duration=10s sys_cpu_logs

table from=201301010930 to= 201301010935  session_FW_fortigate

table window=1m sys_mem_logs

table   limit=10  sys_cpu_logs, sys_mem_logs

table   duration=1m  sys_cpu_logs, sys_mem_logs | limit 10




2-3 fulltext 쿼리 명령어

fulltext “172.19.165.226“ from FW_fortigate

fulltext ipv4(" 172.19.165.226 ") from session_FW_fortigate

fulltext src_ip == ipv4("172.19.165.226") from session_FW_fortigate

fulltext src_port==range(56000,57000) from *

fulltext src_port==range(56000,57000) and src_ip== ipv4("172.19.165.226") from session_FW_fortigate.idx

fulltext duration=2w  "172.19.165.226" from FW_fortigate.idx

fulltext  src_port==range(56000,57000) and src_ip== ipv4("172.19.165.226") from session_FW_fortigate.idx

(참고) table session_FW_fortigate | join src_ip  [table session_FW_fortigate | search action == "deny" | stats count by src_ip | sort limit=1 -count ]
| fields  _time, src_ip, dst_ip, service,action,protocol

fulltext [table session_FW_fortigate | search action == "deny" | stats count by src_ip | sort limit=1 -count]  from session_FW_fortigate.idx
| fields  _time, src_ip, dst_ip, service,action,protocol

fulltext src_ip == ipv4("10.2.64.156") from session_FW_fortigate 
| fields  _time, src_ip, dst_ip, service,action,dst_port, protocol

fulltext  src_port==range(56000,57000) from session_FW_fortigate.idx
| fields _time, src_ip, dst_ip, src_port, dst_port,action, protocol, service

3-1 search 쿼리 명령어

table session_FW_fortigate
| search limit=10000  dst_port  > 300 and dst_port < 400
| fields _time, src_ip,dst_ip, src_port,dst_port, service, protocol

table FW_fortigate| search not(in (src_ip, “192.168.*",“10.*", “172.*"))

search limit=10000 dst_port  > 10000

table session_FW_fortigate | search (ip2long(“172.16.0.0") <= ip2long(dst_ip)) 
               and (ip2long(dst_ip) <=  ip2long(“172.31.255.255"))


3-2  join 쿼리 명령어

json "[ {'code':1}, {'code':2}, {'code':3} ]"   
| join code 
	  [ json " [ {'code':1, 'name':'foo'}, {'code':2, 'name':'bar'} ] " ]

----

json "[ { 'field1': 'A' }, {'field1': 'B'}, {'field1': 'C'}, {'field1': 'D'} ]" 
   | join type=left field1 [ 
    json "[ { 'field1': 'A', 'field2': 'Foo' }, {'field1': 'D', 'field2': 'Bar'} ]" ] 


json "[ { 'field1': 'A' }, {'field1': 'B'}, {'field1': 'C'}, {'field1': 'D'} ]" 
   | join type=leftonly field1 [ 
    json "[ { 'field1': 'A', 'field2': 'Foo' }, {'field1': 'D', 'field2': 'Bar'} ]" ] 

json "[ { 'field1': 'A', 'field2': ‘Joe’ }, {'field1': 'B'}, {'field1': 'C'}, {'field1': 'D'} ]" 
   | join type=left field1 [ json "[ { 'field1': 'A', 'field2': 'Foo' }, {'field1': 'D', 'field2': 'Bar'} ]" ] 


----

json "[ {'id': 1, '건수': 1000}, {'id':2, '건수': 2000} ]" 
| join type=right id [ json " [ {'id':1, '부서':'영업'}, {'id':2, '부서':'운영'}, {'id':3, '부서':'기술'} ] " ]

----

 json "[ {'계정':'xeraph', '문서보안위반': 1}, {'계정':'gotoweb', '문서보안위반': 5}]" 
 | join type=full 계정 [ json " [ {'계정':'gotoweb', '매체제어위반': 8}, {'계정':'stania', '매체제어위반': 3} ] " ]


 3-4 eval 쿼리 명령어
 
 table limit=10000 session_FW_fortigate 
| fields src_ip, dst_ip, recv_bytes, sent_bytes | eval total_bytes = recv_bytes + sent_bytes


table limit=10000 session_FW_fortigate  | stats count

table limit=10000 session_FW_fortigate  | stats count by src_ip

table limit=10000 session_FW_fortigate  | stats sum(recv_bytes) as rbytes_sum , count by src_ip, dst_ip

table limit=10000 session_FW_fortigate  
| stats sum(recv_bytes) as rbytes_sum , count by src_ip, dst_ip 
| sort limit=10 -rbytes_sum 
| eval rb_format = format("%,15d", rbytes_sum)
 
3-5 stats
table from=201301010300 to=201301010400 session_FW_fortigate
| limit 1000
| pivot count by service, dst_port,protocol
| join dst_port [ table Port | rename PortNumberL as dst_port
| stats first(Description) as Description by dst_port]
| eval service = upper(service)
| stats sum(count) as count by Description | sort -count
 
4. 함수 (2/4)

json “{}” | eval today=now() | eval tomorrow= dateadd(today, “day”,1)

json “{}” | eval greetings = concat(“Hello”, “  “, “World !”)

4. 함수(3/4)

# set from=if(isnull($("from")),ago(“-90d”), $("from")) 
| set from=if(isnull($("from")),dateadd(now(), "day", -90), $("from")) 
| set to=if(isnull($("to")), now(), $("to")) 
| table from=$("from") to=$("to")  FW_fortigate

###################

json "{}"
| eval _time = daterange(dateadd(now(), "day", -7), dateadd(now(), "day", 7)) 
| explode _time | eval _time = datetrunc(_time, "1d")
| eval dow_day = datepart(_time, "dow")
| eval isodow_day = datepart(_time, "isodow")
| # 다음 str(ing)은 문자열 함수
| eval 요일 = str(_time, "E") 

---------------전주 금주 CPU 사용량 비교
set from=if(isnull($("from")),dateadd(now(), "day", -14), $("from")) 
| set to=if(isnull($("to")), now(), $("to")) 
| table from=$("from") to=$("to")  sys_cpu_logs
| # stats min(_time) as start, max(_time) as end 
| eval _time = datetrunc(_time, "1d")
| stats avg(idle) as idle, avg(kernel) as kernel, avg(user) as user by _time
| join  type=right _time [json "{}" 
| eval _time = daterange(dateadd(now(), "day", -14), dateadd(now(), "day", 7)) 
| explode _time 
| eval _time = datetrunc(_time, "1d") 
| eval td = int(str(now(), "w")), wd = int(str(_time, "w")), chk = td - wd, chk = if(chk< -51, 53+chk, chk), day = str(_time, "E") 
| search in(chk, 0, 1, -51) | sort limit=14  -chk 
| sort _time | fields _time, day, chk ]
| rename idle as 전주_idle, kernel as 전주_kernel, user as 전주_user 
| search chk == 1
| join day [
set from=if(isnull($("from")),dateadd(now(), "day", -14), $("from")) 
| set to=if(isnull($("to")), now(), $("to")) 
| table from=$("from") to=$("to")  sys_cpu_logs
| # stats min(_time) as start, max(_time) as end 
| eval _time = datetrunc(_time, "1d")
| stats avg(idle) as idle, avg(kernel) as kernel, avg(user) as user by _time
| join  type=right _time [json "{}" 
| eval _time = daterange(dateadd(now(), "day", -14), dateadd(now(), "day", 7)) 
| explode _time 
| eval _time = datetrunc(_time, "1d") 
| eval td = int(str(now(), "w")), wd = int(str(_time, "w")), chk = td - wd, chk = if(chk< -51, 53+chk, chk), day = str(_time, "E") 
| search in(chk, 0, 1, -51) | sort limit=14  -chk 
| sort _time | fields _time, day, chk ]
| search chk == 0 | rename idle as 금주_idle, kernel as 금주_kernel, user as 금주_user ]




5-2. import

   set filepath = concat("D:\\logsample\\fortigate\\fortigate", ".log") 
| textfile $("filepath") 
| limit 100 
|  # parse fgate 
| # summary


----

set filepath = concat("D:\\logsample\\fortigate\\fortigate", ".log") 
| textfile $("filepath") 
| import FW_fortigate





5-3 outputcsv

1. 방화벽 로그로 부터 송수신 트래픽을 1분단위로 집계하여 csv파일로 export하는 경우

   set filepath = concat("D:\\logsample\\fortigate\\송수신_traffic_1m", ".csv")
| table session_FW_fortigate 
| timechart span=1m sum(sent_bytes) as sent_bytes, sum(recv_bytes) as recv_bytes 
| eval time = string(_time, "yyyy-MM-dd HH:mm:ss")
|  outputcsv overwrite=t $("filepath")   time, sent_bytes, recv_bytes

----

.수고하셨습니다!!
